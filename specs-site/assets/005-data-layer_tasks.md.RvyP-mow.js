import{_ as r,C as t,o,c as i,an as c,b as l,w as d,a as s,E as n,ao as u}from"./chunks/framework.CTqRDTHW.js";const S=JSON.parse('{"title":"Tasks: Data Layer Services Setup","description":"","frontmatter":{},"headers":[],"relativePath":"005-data-layer/tasks.md","filePath":"005-data-layer/tasks.md","lastUpdated":1772310733000}'),p={name:"005-data-layer/tasks.md"};function h(m,e,v,b,g,f){const a=t("Mermaid");return o(),i("div",null,[e[1]||(e[1]=c(`<h1 id="tasks-data-layer-services-setup" tabindex="-1">Tasks: Data Layer Services Setup <a class="header-anchor" href="#tasks-data-layer-services-setup" aria-label="Permalink to &quot;Tasks: Data Layer Services Setup&quot;">​</a></h1><blockquote><p><strong>Spec</strong>: 005-data-layer <strong>Date</strong>: 2026-02-28</p></blockquote><h2 id="task-format" tabindex="-1">Task Format <a class="header-anchor" href="#task-format" aria-label="Permalink to &quot;Task Format&quot;">​</a></h2><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>[TASK-NNN] [P?] [MODULE] [PRIORITY] Description</span></span>
<span class="line"><span>  Dependencies: [TASK-XXX] or none</span></span>
<span class="line"><span>  Module: services/{role}</span></span>
<span class="line"><span>  Acceptance: Testable criteria</span></span>
<span class="line"><span>  Status: [ ] pending | [~] in-progress | [x] done</span></span></code></pre></div><ul><li><code>[P]</code> = Safe for parallel agent execution</li><li>Priority: P1 (must), P2 (should), P3 (nice)</li></ul><h2 id="dependency-graph" tabindex="-1">Dependency Graph <a class="header-anchor" href="#dependency-graph" aria-label="Permalink to &quot;Dependency Graph&quot;">​</a></h2>`,6)),(o(),l(u,null,{default:d(()=>[n(a,{id:"mermaid-27",class:"mermaid",graph:"graph%20TD%0A%20%20%20%20T001%5B%22TASK-001%5Cnprofiles.yaml%22%5D%20--%3E%20T011%0A%20%20%20%20T001%20--%3E%20T012%0A%20%20%20%20T001%20--%3E%20T013%0A%0A%20%20%20%20T011%5B%22TASK-011%20%5BP%5D%5Cnservices%2Fpersistence%2F%5CnOracle%22%5D%20--%3E%20T021%0A%20%20%20%20T012%5B%22TASK-012%20%5BP%5D%5Cnservices%2Fvector%2F%5CnCerebro%22%5D%20--%3E%20T022%0A%20%20%20%20T013%5B%22TASK-013%20%5BP%5D%5Cnservices%2Fstorage%2F%5CnTardis%22%5D%20--%3E%20T023%0A%0A%20%20%20%20T021%5B%22TASK-021%20%5BP%5D%5Cnoracle.mk%22%5D%20--%3E%20T024%0A%20%20%20%20T022%5B%22TASK-022%20%5BP%5D%5Cncerebro.mk%22%5D%20--%3E%20T024%0A%20%20%20%20T023%5B%22TASK-023%20%5BP%5D%5Cntardis.mk%22%5D%20--%3E%20T024%0A%0A%20%20%20%20T024%5B%22TASK-024%5Cndata.mk%20%2B%5CnMakefile%20includes%22%5D%20--%3E%20T031%0A%20%20%20%20T024%20--%3E%20T032%0A%0A%20%20%20%20T031%5B%22TASK-031%20%5BP%5D%5Cndata-images.yml%22%5D%20--%3E%20T041%0A%20%20%20%20T032%5B%22TASK-032%20%5BP%5D%5Cndata-release.yml%22%5D%20--%3E%20T041%0A%0A%20%20%20%20T041%5B%22TASK-041%5CnE2E%20verification%22%5D%20--%3E%20T900%0A%20%20%20%20T041%20--%3E%20T999%0A%0A%20%20%20%20T900%5B%22TASK-900%5CnDocs%20%26%20links%22%5D%20--%3E%20T999%0A%20%20%20%20T999%5B%22TASK-999%5CnReviewer%22%5D%0A"})]),fallback:d(()=>[...e[0]||(e[0]=[s(" Loading... ",-1)])]),_:1})),e[2]||(e[2]=c('<h2 id="quality-requirements" tabindex="-1">Quality Requirements <a class="header-anchor" href="#quality-requirements" aria-label="Permalink to &quot;Quality Requirements&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Module</th><th>Coverage</th><th>Lint</th><th>Notes</th></tr></thead><tbody><tr><td>Config/YAML</td><td>n/a</td><td><code>docker compose config</code> (no syntax errors)</td><td></td></tr><tr><td>Makefile</td><td>n/a</td><td><code>make -n {target}</code> dry-run passes</td><td></td></tr><tr><td>CI/CD YAML</td><td>n/a</td><td>GitHub Actions YAML schema valid</td><td></td></tr></tbody></table><hr><h2 id="phase-1-setup" tabindex="-1">Phase 1: Setup <a class="header-anchor" href="#phase-1-setup" aria-label="Permalink to &quot;Phase 1: Setup&quot;">​</a></h2><ul><li>[x] [TASK-001] [SERVICES] [P1] Update profiles.yaml — oracle + cerebro → <code>think</code>; tardis → <code>reason</code><ul><li>Dependencies: none</li><li>Module: <code>services/profiles.yaml</code></li><li>Acceptance: <ul><li><code>grep &quot;oracle&quot; services/profiles.yaml</code> matches a line under <code>think.services</code></li><li><code>grep &quot;cerebro&quot; services/profiles.yaml</code> matches a line under <code>think.services</code></li><li><code>grep &quot;tardis&quot; services/profiles.yaml</code> matches a line under <code>reason.services</code></li><li><code>ultra-instinct</code> entry unchanged (<code>services: &#39;*&#39;</code>)</li><li>File parses as valid YAML: <code>python3 -c &quot;import yaml,sys; yaml.safe_load(open(&#39;services/profiles.yaml&#39;))&quot;</code> exits 0</li></ul></li></ul></li></ul><hr><h2 id="phase-2-foundational-—-service-directories-parallel" tabindex="-1">Phase 2: Foundational — Service Directories (parallel) <a class="header-anchor" href="#phase-2-foundational-—-service-directories-parallel" aria-label="Permalink to &quot;Phase 2: Foundational — Service Directories (parallel)&quot;">​</a></h2><p>All three tasks are fully independent. Each creates 4 files: <code>Dockerfile</code>, <code>service.yaml</code>, <code>docker-compose.yml</code>, and the <code>.mk</code> file is handled in Phase 3.</p><ul><li><p>[x] [TASK-011] [P] [SERVICES] [P1] Create <code>services/persistence/</code> — Oracle (Postgres 17)</p><ul><li>Dependencies: TASK-001</li><li>Module: <code>services/persistence/</code></li><li>Acceptance: <ul><li><code>Dockerfile</code>: <code>FROM postgres:17-alpine</code>; OCI labels (<code>org.opencontainers.image.title</code>, <code>source</code>); <code>arc.service.name=arc-sql-db</code>, <code>arc.service.codename=oracle</code>, <code>arc.service.tech=postgres</code>; no USER directive (postgres user uid 70 is default)</li><li><code>service.yaml</code>: name <code>arc-sql-db</code>, codename <code>oracle</code>, image <code>ghcr.io/arc-framework/arc-sql-db:latest</code>, tech <code>postgres</code>, upstream <code>postgres:17-alpine</code>, ports <code>[5432]</code>, health <code>pg_isready -U arc</code>, depends_on <code>[]</code></li><li><code>docker-compose.yml</code>: service <code>arc-sql-db</code>; env <code>POSTGRES_USER=arc POSTGRES_PASSWORD=arc POSTGRES_DB=arc</code>; port <code>127.0.0.1:5432:5432</code>; volume <code>arc-sql-db-data:/var/lib/postgresql/data</code>; healthcheck <code>pg_isready -U arc || exit 1</code> interval 5s, timeout 3s, retries 10, start_period 10s; network <code>arc_platform_net</code> (external); <code>restart: unless-stopped</code></li><li><code>docker compose config</code> passes without errors</li><li><code>docker build -f services/persistence/Dockerfile services/persistence/</code> succeeds</li></ul></li><li>Reviewer notes (2026-02-28): All acceptance criteria verified. <code>docker exec arc-sql-db ps aux</code> confirms <code>postgres</code> user (uid 70) runs the postgres process. PASS.</li></ul></li><li><p>[x] [TASK-012] [P] [SERVICES] [P1] Create <code>services/vector/</code> — Cerebro (Qdrant)</p><ul><li>Dependencies: TASK-001</li><li>Module: <code>services/vector/</code></li><li>Acceptance: <ul><li><code>Dockerfile</code>: <code>FROM qdrant/qdrant</code>; OCI labels; <code>arc.service.name=arc-vector-db</code>, <code>arc.service.codename=cerebro</code>, <code>arc.service.tech=qdrant</code>; no USER directive (qdrant image runs as uid 1000)</li><li><code>service.yaml</code>: name <code>arc-vector-db</code>, codename <code>cerebro</code>, image <code>ghcr.io/arc-framework/arc-vector-db:latest</code>, tech <code>qdrant</code>, upstream <code>qdrant/qdrant</code>, ports <code>[6333, 6334]</code>, health <code>http://localhost:6333/readyz</code>, depends_on <code>[]</code></li><li><code>docker-compose.yml</code>: service <code>arc-vector-db</code>; ports <code>127.0.0.1:6333:6333</code> and <code>127.0.0.1:6334:6334</code>; volume <code>arc-vector-db-data:/qdrant/storage</code>; healthcheck <code>wget -qO- http://localhost:6333/readyz || exit 1</code> interval 5s, timeout 3s, retries 5, start_period 5s; network <code>arc_platform_net</code> (external); <code>restart: unless-stopped</code></li><li><code>docker compose config</code> passes without errors</li><li><code>docker build -f services/vector/Dockerfile services/vector/</code> succeeds</li></ul></li><li>Reviewer notes (2026-02-28): BLOCKED — Constitution Principle VIII violation. <ul><li>The <code>qdrant/qdrant</code> upstream image declares <code>USER 0:0</code> (root) by default. The <code>USER_ID</code> build arg defaults to 0. <code>docker inspect arc-vector-db --format &#39;{{.Config.User}}&#39;</code> returns <code>0:0</code> and <code>docker exec arc-vector-db whoami</code> returns <code>root</code>.</li><li>The Dockerfile comment &quot;qdrant image runs as uid 1000 by default&quot; is factually incorrect — the upstream image runs as root unless the image is rebuilt with <code>--build-arg USER_ID=1000</code>.</li><li>Acceptance criterion says &quot;no USER directive (qdrant image runs as uid 1000)&quot; — this is wrong. A <code>user: &quot;1000:1000&quot;</code> entry must be added to <code>services/vector/docker-compose.yml</code> (same approach as Tardis), or the Dockerfile must rebuild with <code>--build-arg USER_ID=1000</code> and add <code>USER 1000</code>.</li><li>Acceptable healthcheck deviation (pre-approved): compose healthcheck uses <code>bash -c &#39;exec 3&lt;&gt;/dev/tcp/...&#39;</code> instead of <code>wget</code> because <code>wget</code> is not present in the qdrant image. Functional result is identical (HTTP 200 check on /readyz).</li></ul></li><li>Re-verification (2026-02-28): PASS. Dockerfile now adds USER root, pre-creates /qdrant/storage + /qdrant/snapshots with chown 1000:1000, then drops to USER 1000. docker-compose.yml adds <code>user: &quot;1000:1000&quot;</code>. Verified: <code>docker inspect arc-vector-db --format &#39;{{.Config.User}}&#39;</code> = <code>1000:1000</code>; <code>docker exec arc-vector-db id</code> = <code>uid=1000 gid=1000 groups=1000</code>. Principle VIII satisfied. PASS.</li></ul></li><li><p>[x] [TASK-013] [P] [SERVICES] [P1] Create <code>services/storage/</code> — Tardis (MinIO)</p><ul><li>Dependencies: TASK-001</li><li>Module: <code>services/storage/</code></li><li>Acceptance: <ul><li><code>Dockerfile</code>: <code>FROM minio/minio</code>; OCI labels; <code>arc.service.name=arc-storage</code>, <code>arc.service.codename=tardis</code>, <code>arc.service.tech=minio</code>; document uid in comment (non-root if supported, otherwise note deviation per 003-Pulsar pattern)</li><li><code>service.yaml</code>: name <code>arc-storage</code>, codename <code>tardis</code>, image <code>ghcr.io/arc-framework/arc-storage:latest</code>, tech <code>minio</code>, upstream <code>minio/minio</code>, ports <code>[9000, 9001]</code>, health <code>http://localhost:9000/minio/health/live</code>, depends_on <code>[]</code></li><li><code>docker-compose.yml</code>: service <code>arc-storage</code>; command <code>server /data --console-address &quot;:9001&quot;</code>; env <code>MINIO_ROOT_USER=arc MINIO_ROOT_PASSWORD=arc-minio-dev</code>; ports <code>127.0.0.1:9000:9000</code> and <code>127.0.0.1:9001:9001</code>; volume <code>arc-storage-data:/data</code>; healthcheck <code>curl -f http://localhost:9000/minio/health/live || exit 1</code> interval 10s, timeout 5s, retries 5, start_period 10s; network <code>arc_platform_net</code> (external); <code>restart: unless-stopped</code></li><li><code>docker compose config</code> passes without errors</li><li><code>docker build -f services/storage/Dockerfile services/storage/</code> succeeds</li><li>Non-root uid: attempt <code>user: &quot;1000:1000&quot;</code> in docker-compose first; if MinIO fails to start, try <code>USER 1000</code> in Dockerfile; if both fail, add inline comment <code># NOTE: minio/minio requires root — upstream constraint</code> (same as Pulsar in 003)</li></ul></li><li>Reviewer notes (2026-02-28): <code>user: &quot;1000:1000&quot;</code> confirmed in compose; <code>docker inspect arc-storage --format &#39;{{.Config.User}}&#39;</code> returns <code>1000:1000</code>; <code>docker exec arc-storage id</code> returns <code>uid=1000 gid=1000</code>. Dockerfile pre-creates <code>/data</code> owned by uid 1000 and drops to <code>USER 1000</code>. PASS.</li></ul></li></ul><hr><h2 id="phase-3-make-targets" tabindex="-1">Phase 3: Make Targets <a class="header-anchor" href="#phase-3-make-targets" aria-label="Permalink to &quot;Phase 3: Make Targets&quot;">​</a></h2><p>Batch A (parallel — each .mk is independent):</p><ul><li><p>[x] [TASK-021] [P] [SERVICES] [P1] Create <code>services/persistence/oracle.mk</code></p><ul><li>Dependencies: TASK-011</li><li>Module: <code>services/persistence/oracle.mk</code></li><li>Acceptance: <ul><li>Targets present: <code>oracle-help</code>, <code>oracle-build</code>, <code>oracle-build-fresh</code>, <code>oracle-up</code>, <code>oracle-down</code>, <code>oracle-health</code>, <code>oracle-logs</code>, <code>oracle-push</code>, <code>oracle-publish</code>, <code>oracle-tag</code>, <code>oracle-clean</code>, <code>oracle-nuke</code></li><li><code>oracle-health</code>: probes <code>pg_isready -U arc -h localhost -p 5432</code>; exits 0 if healthy, 1 if not</li><li><code>oracle-clean</code> / <code>oracle-nuke</code>: require typed confirmation (<code>yes</code> / <code>nuke</code>) before destructive action</li><li><code>oracle-publish</code>: pushes image then prints <code>https://github.com/orgs/$(ORG)/packages/container/arc-sql-db/settings</code></li><li><code>make oracle-help</code> lists all targets with descriptions</li><li>All targets use <code>COLOR_INFO</code>, <code>COLOR_OK</code>, <code>COLOR_ERR</code> inherited from root Makefile</li><li>All paths relative to repo root</li></ul></li></ul></li><li><p>[x] [TASK-022] [P] [SERVICES] [P1] Create <code>services/vector/cerebro.mk</code></p><ul><li>Dependencies: TASK-012</li><li>Module: <code>services/vector/cerebro.mk</code></li><li>Acceptance: <ul><li>Targets present: <code>cerebro-help</code>, <code>cerebro-build</code>, <code>cerebro-build-fresh</code>, <code>cerebro-up</code>, <code>cerebro-down</code>, <code>cerebro-health</code>, <code>cerebro-logs</code>, <code>cerebro-push</code>, <code>cerebro-publish</code>, <code>cerebro-tag</code>, <code>cerebro-clean</code>, <code>cerebro-nuke</code></li><li><code>cerebro-health</code>: probes <code>wget -qO- http://localhost:6333/readyz</code>; exits 0 if healthy, 1 if not</li><li><code>cerebro-clean</code> / <code>cerebro-nuke</code>: require typed confirmation before destructive action</li><li><code>cerebro-publish</code>: pushes then prints settings URL</li><li><code>make cerebro-help</code> lists all targets</li></ul></li><li>Reviewer notes (2026-02-28): All targets present and function correctly. Minor acceptable deviation: <code>cerebro-health</code> in the .mk uses <code>curl -sf</code> (not <code>wget</code>) to probe from the host — functionally identical. PASS.</li></ul></li><li><p>[x] [TASK-023] [P] [SERVICES] [P1] Create <code>services/storage/tardis.mk</code></p><ul><li>Dependencies: TASK-013</li><li>Module: <code>services/storage/tardis.mk</code></li><li>Acceptance: <ul><li>Targets present: <code>tardis-help</code>, <code>tardis-build</code>, <code>tardis-build-fresh</code>, <code>tardis-up</code>, <code>tardis-down</code>, <code>tardis-health</code>, <code>tardis-logs</code>, <code>tardis-push</code>, <code>tardis-publish</code>, <code>tardis-tag</code>, <code>tardis-clean</code>, <code>tardis-nuke</code></li><li><code>tardis-health</code>: probes <code>curl -f http://localhost:9000/minio/health/live</code>; exits 0 if healthy, 1 if not</li><li><code>tardis-clean</code> / <code>tardis-nuke</code>: require typed confirmation before destructive action</li><li><code>tardis-publish</code>: pushes then prints settings URL</li><li><code>make tardis-help</code> lists all targets</li></ul></li></ul></li></ul><p>Batch B (sequential — depends on all Batch A):</p><ul><li>[x] [TASK-024] [SERVICES] [P1] Create <code>services/data.mk</code> + update root <code>Makefile</code> includes <ul><li>Dependencies: TASK-021, TASK-022, TASK-023</li><li>Module: <code>services/data.mk</code>, <code>Makefile</code></li><li>Acceptance: <ul><li><code>services/data.mk</code> targets: <code>data-help</code>, <code>data-up</code>, <code>data-down</code>, <code>data-health</code>, <code>data-logs</code></li><li><code>data-up</code>: calls <code>docker network create arc_platform_net 2&gt;/dev/null || true</code>, then <code>oracle-up</code>, <code>cerebro-up</code>, <code>tardis-up</code> sequentially</li><li><code>data-down</code>: calls <code>oracle-down</code>, <code>cerebro-down</code>, <code>tardis-down</code> sequentially</li><li><code>data-health</code>: calls all three health targets; exits non-zero if any fails</li><li><code>data-logs</code>: fans out logs from all three containers simultaneously with service name prefixes</li><li>Root <code>Makefile</code>: <code>include services/persistence/oracle.mk</code>, <code>include services/vector/cerebro.mk</code>, <code>include services/storage/tardis.mk</code>, <code>include services/data.mk</code> added after existing service includes</li><li><code>make data-help</code> lists data-* targets</li><li><code>make -n data-up</code> dry-run shows correct chain</li></ul></li></ul></li></ul><hr><h2 id="phase-4-ci-cd-parallel" tabindex="-1">Phase 4: CI/CD (parallel) <a class="header-anchor" href="#phase-4-ci-cd-parallel" aria-label="Permalink to &quot;Phase 4: CI/CD (parallel)&quot;">​</a></h2><p>Both workflows are independent and can be implemented concurrently.</p><ul><li><p>[x] [TASK-031] [P] [CI] [P1] Create <code>.github/workflows/data-images.yml</code></p><ul><li>Dependencies: TASK-024</li><li>Module: <code>.github/workflows/data-images.yml</code></li><li>Acceptance: <ul><li>Mirrors <code>messaging-images.yml</code> structure exactly</li><li><code>on.push.paths</code>: <code>services/persistence/**</code>, <code>services/vector/**</code>, <code>services/storage/**</code>, <code>.github/workflows/data-images.yml</code></li><li><code>on.pull_request.paths</code>: same service paths</li><li><code>on.workflow_dispatch</code> with <code>mode</code> input (<code>ci</code> / <code>release</code>)</li><li><code>changes</code> job uses <code>dorny/paths-filter@v3</code> with filters <code>oracle</code>, <code>cerebro</code>, <code>tardis</code></li><li><code>build-oracle</code>, <code>build-cerebro</code>, <code>build-tardis</code> jobs: parallel, each uses <code>_reusable-build.yml</code><ul><li><code>platforms: linux/amd64</code></li><li><code>service-path: services/persistence</code> / <code>services/vector</code> / <code>services/storage</code></li></ul></li><li><code>security-oracle</code>, <code>security-cerebro</code>, <code>security-tardis</code> jobs: run after respective builds; <code>block-on-failure: false</code> in CI; <code>_reusable-security.yml</code></li><li>YAML is valid; <code>act</code> dry-run passes if available</li></ul></li></ul></li><li><p>[x] [TASK-032] [P] [CI] [P1] Create <code>.github/workflows/data-release.yml</code></p><ul><li>Dependencies: TASK-024</li><li>Module: <code>.github/workflows/data-release.yml</code></li><li>Acceptance: <ul><li>Mirrors <code>messaging-release.yml</code> structure exactly</li><li><code>on.push.tags</code>: <code>data/v*</code></li><li><code>prepare</code> job: derives <code>image-tag</code> (<code>data/v0.1.0</code> → <code>data-v0.1.0</code>), <code>version</code>, <code>prerelease</code> outputs</li><li><code>build-oracle</code>, <code>build-cerebro</code>, <code>build-tardis</code>: parallel after <code>prepare</code>; <code>platforms: linux/amd64,linux/arm64</code>; <code>push-image: true</code>, <code>latest-tag: true</code>, <code>image-tag: ${{ needs.prepare.outputs.image-tag }}</code></li><li><code>security-oracle</code>, <code>security-cerebro</code>, <code>security-tardis</code>: <code>block-on-failure: true</code>; <code>create-issues: true</code> (CRITICAL CVEs block release)</li><li><code>release</code> job: generates release notes with image table (arc-sql-db, arc-vector-db, arc-storage); creates GitHub release via <code>softprops/action-gh-release@v2</code></li><li>Release notes include <code>make data-up</code> / <code>make data-health</code> quick-start</li><li>YAML is valid</li></ul></li></ul></li></ul><hr><h2 id="phase-5-integration" tabindex="-1">Phase 5: Integration <a class="header-anchor" href="#phase-5-integration" aria-label="Permalink to &quot;Phase 5: Integration&quot;">​</a></h2><ul><li>[x] [TASK-041] [SERVICES] [P1] End-to-end verification — data layer up + health <ul><li>Dependencies: TASK-031, TASK-032</li><li>Module: <code>services/persistence/</code>, <code>services/vector/</code>, <code>services/storage/</code></li><li>Acceptance: <ul><li><code>docker network create arc_platform_net 2&gt;/dev/null || true</code> runs without error</li><li><code>make data-up</code> exits 0; <code>docker compose ps</code> shows arc-sql-db, arc-vector-db, arc-storage all in <code>healthy</code> state</li><li><code>make data-health</code> exits 0 (all three health probes pass)</li><li><code>make data-down</code> exits 0; all three containers stop; no orphaned containers</li><li>Independent health checks pass: <code>make oracle-health</code>, <code>make cerebro-health</code>, <code>make tardis-health</code></li><li><code>curl -s http://localhost:6333/readyz</code> returns HTTP 200</li><li><code>curl -s http://localhost:9000/minio/health/live</code> returns HTTP 200</li><li><code>docker exec arc-sql-db pg_isready -U arc</code> exits 0</li><li>All ports bound to <code>127.0.0.1</code>: <code>docker compose ps</code> confirms</li><li>All volumes are named: <code>docker volume ls | grep arc</code> shows <code>arc-sql-db-data</code>, <code>arc-vector-db-data</code>, <code>arc-storage-data</code></li><li>After <code>make data-up</code> + <code>make cortex-docker-up</code>: <code>curl -s http://localhost:8081/health/deep | jq .oracle.status</code> returns <code>&quot;ok&quot;</code></li></ul></li><li>Reviewer notes (2026-02-28): 10 of 11 criteria PASS. BLOCKED on TASK-012 (Cerebro runs as root). <ul><li>Criteria 1-10 all verified and passing in live test.</li><li>Criterion 11 (Cortex oracle health): <code>&quot;ok&quot;: false</code> — FAIL. Root cause is a pre-existing mismatch in Cortex config (commit 1d15b07): Cortex defaults <code>bootstrap.postgres.db=arc_db</code> and has no password configured, while Oracle compose sets <code>POSTGRES_DB=arc</code> and <code>POSTGRES_PASSWORD=arc</code>. This is not introduced by 005-data-layer. The implementer must align either Cortex&#39;s config or Oracle&#39;s env (or both) and document in Cortex&#39;s compose. This criterion blocks TASK-041 until resolved.</li></ul></li><li>Re-verification (2026-02-28): ALL 11 criteria PASS. <ul><li>Criterion 11 fix: <code>services/cortex/internal/config/config.go</code> now sets default <code>bootstrap.postgres.password=&quot;&quot;</code> and <code>bootstrap.postgres.db=&quot;arc&quot;</code> (was <code>arc_db</code>). <code>services/cortex/docker-compose.yml</code> injects <code>CORTEX_BOOTSTRAP_POSTGRES_PASSWORD: arc</code>. <code>curl -s http://localhost:8081/health/deep | jq .dependencies.postgres</code> = <code>{&quot;name&quot;:&quot;arc-sql-db&quot;,&quot;ok&quot;:true,&quot;latencyMs&quot;:17}</code>. PASS.</li></ul></li></ul></li></ul><hr><h2 id="phase-6-polish" tabindex="-1">Phase 6: Polish <a class="header-anchor" href="#phase-6-polish" aria-label="Permalink to &quot;Phase 6: Polish&quot;">​</a></h2><ul><li><p>[x] [TASK-900] [P] [DOCS] [P1] Docs &amp; links update</p><ul><li>Dependencies: TASK-041</li><li>Module: <code>services/profiles.yaml</code>, <code>CLAUDE.md</code>, <code>services/cortex/service.yaml</code></li><li>Acceptance: <ul><li><code>services/profiles.yaml</code> <code>think</code> profile includes <code>oracle</code> and <code>cerebro</code> (already done in TASK-001 — verify final state)</li><li><code>services/profiles.yaml</code> <code>reason</code> profile includes <code>tardis</code></li><li><code>services/cortex/service.yaml</code> <code>depends_on</code> field references <code>oracle</code> codename (add if missing)</li><li><code>CLAUDE.md</code> monorepo layout section references <code>persistence/</code>, <code>vector/</code>, <code>storage/</code> directories (add if missing)</li><li>No broken internal references in modified files</li></ul></li><li>Reviewer notes (2026-02-28): All docs criteria pass. CLAUDE.md monorepo layout lists all three directories; service codenames table updated. cortex/service.yaml depends_on includes <code>oracle</code>. PASS.</li></ul></li><li><p>[x] [TASK-999] [REVIEW] [P1] Reviewer agent verification</p><ul><li>Dependencies: ALL</li><li>Module: all affected modules</li><li>Acceptance (reviewer runs all items from plan.md Reviewer Checklist): <ul><li>All tasks TASK-001 through TASK-900 marked complete</li><li><code>make data-up &amp;&amp; make data-health</code> exits 0</li><li><code>make data-down</code> clean shutdown</li><li>Cortex <code>/health/deep</code> shows <code>oracle: ok</code></li><li>All ports bind <code>127.0.0.1</code></li><li>All volumes are named Docker volumes</li><li><code>profiles.yaml</code> think includes oracle + cerebro; reason includes tardis</li><li><code>Makefile</code> includes oracle.mk, cerebro.mk, tardis.mk, data.mk</li><li><code>data-images.yml</code> path filters cover all three service directories</li><li><code>data-release.yml</code> tag format <code>data/v*</code>; multi-platform builds</li><li>All Dockerfiles have OCI + <code>arc.service.*</code> labels</li><li>No credentials in any compose file</li><li><code>docker inspect arc-sql-db</code> confirms postgres uid 70 (non-root default)</li><li><code>docker inspect arc-vector-db</code> confirms uid 1000 (non-root)</li><li>MinIO uid documented (non-root or deviation noted in compose comments)</li><li>Constitution compliance: II, III, IV, V, VII, VIII, XI all PASS</li></ul></li><li>Reviewer notes (2026-02-28): BLOCKED — two issues must be resolved before this can be marked done. <ul><li>ISSUE-1 (CRITICAL): <code>docker inspect arc-vector-db</code> shows <code>Config.User=0:0</code>; runtime <code>id</code> returns <code>uid=0(root)</code>. The upstream <code>qdrant/qdrant</code> image defaults to <code>USER 0:0</code>. Principle VIII (non-root containers) is violated. Fix: add <code>user: &quot;1000:1000&quot;</code> to <code>services/vector/docker-compose.yml</code> and rebuild (same pattern as Tardis), or rebuild Dockerfile with <code>--build-arg USER_ID=1000</code> and add <code>USER 1000</code>. Correct the Dockerfile comment from &quot;qdrant image runs as uid 1000 by default&quot; to reflect the actual fix.</li><li>ISSUE-2 (BLOCKER): <code>curl .../health/deep | jq &#39;.dependencies.postgres.ok&#39;</code> returns <code>false</code>. Root cause: pre-existing mismatch between Cortex defaults (<code>arc_db</code>, no password) and Oracle compose (<code>POSTGRES_DB=arc</code>, <code>POSTGRES_PASSWORD=arc</code>). Fix: align Oracle <code>POSTGRES_DB</code> to <code>arc_db</code>, or configure <code>POSTGRES_DB=arc_db</code> and add <code>BOOTSTRAP_POSTGRES_PASSWORD=arc</code> env in <code>services/cortex/docker-compose.yml</code>. Needs coordination with Cortex maintainer.</li></ul></li><li>Re-verification (2026-02-28): ALL checklist items PASS. Both issues resolved. See TASK-012 and TASK-041 re-verification notes. APPROVED.</li></ul></li></ul><hr><h2 id="progress-summary" tabindex="-1">Progress Summary <a class="header-anchor" href="#progress-summary" aria-label="Permalink to &quot;Progress Summary&quot;">​</a></h2><table tabindex="0"><thead><tr><th>Phase</th><th>Total</th><th>Done</th><th>Blocked</th></tr></thead><tbody><tr><td>Setup</td><td>1</td><td>1</td><td>0</td></tr><tr><td>Foundational</td><td>3</td><td>3</td><td>0</td></tr><tr><td>Implementation (Make + CI)</td><td>6</td><td>6</td><td>0</td></tr><tr><td>Integration</td><td>1</td><td>1</td><td>0</td></tr><tr><td>Polish</td><td>2</td><td>2</td><td>0</td></tr><tr><td><strong>Total</strong></td><td><strong>13</strong></td><td><strong>13</strong></td><td><strong>0</strong></td></tr></tbody></table><p>All tasks complete. Re-verified 2026-02-28.</p>',29))])}const A=r(p,[["render",h]]);export{S as __pageData,A as default};
